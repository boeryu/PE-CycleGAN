#!/usr/bin/python3

import argparse
import sys
import os
import numpy as np
import tifffile
from utils import *
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import torch
from torch.xpu import device

from models import Generator3D
from datasets import VolumeDataset

parser = argparse.ArgumentParser()
parser.add_argument('--batchSize', type=int, default=1, help='size of the batches')
parser.add_argument('--dataroot', type=str,required=True, default='datasets/l2r/', help='root directory of the dataset')
parser.add_argument('--input_nc', type=int, default=1, help='number of channels of input data')
parser.add_argument('--output_nc', type=int, default=1, help='number of channels of output data')
parser.add_argument('--volume_shape', type=int,nargs=3, default=[16,1432,1432], help='size of the data crop (squared assumed)')
parser.add_argument('--cuda', action='store_true', help='use GPU computation')
parser.add_argument('--n_cpu', type=int, default=0, help='number of cpu threads to use during batch generation')
parser.add_argument('--generator_B2A', type=str, required=True,default='output/netG_B2A.pth', help='B2A generator checkpoint file')
parser.add_argument('--dropout', type=bool, default=False, help='')
opt = parser.parse_args()
print(opt)

device = torch.device("cuda" if opt.cuda and torch.cuda.is_available() else "cpu")
if device.type =='cuda':
    torch.backends.cudnn.benchmark = True
###### Definition of variables ######
# Networks

netG_B2A = Generator3D(opt.output_nc, opt.input_nc).to(device)

def load_model(model,checkpoint_path):
    if os.path.isfile(checkpoint_path):
        model.load_state_dict(torch.load(checkpoint_path,map_location=device))
        print(f"Loaded{checkpoint_path}")
    else:
        raise  FileNotFoundError(f"Checkpoint{checkpoint_path}not found")

load_model(netG_B2A,opt.generator_B2A)

# Set model's test mode

netG_B2A.eval()

test_transform = ([

    transforms.Lambda(lambda x: _auto_adjust_dims(x)),
    transforms.Lambda(lambda x: x.float()),
    FixedDepthCrop3D(opt.volume_shape),
    transforms.Lambda(lambda x: (x-x.min())/(x.max()-x.min())*2-1)

])
def _auto_adjust_dims(tensor):
    original_dims=tensor.dim()
    if tensor.dim()==3:
        tensor = tensor.unsqueeze(0).unsqueeze(0)
    elif tensor.dim()==4:
        tensor = tensor.unsqueeze(0)
    elif tensor.dim()==5:
      pass
    return tensor
test_dataset = VolumeDataset(
    root = opt.dataroot,
    transforms_=test_transform,
    mode='test'
)

dataloader = DataLoader(
    test_dataset,
    batch_size=opt.batchSize,
    shuffle=False,
    num_workers=opt.n_cpu,
    collate_fn=lambda x: x[0]
)


###### Testing######

# Create output dirs if they don't exist
output_dir_A= 'output/tubulins/A'

os.makedirs(output_dir_A,exist_ok=True)

with torch.no_grad():
    for i, batch in enumerate(dataloader):


      real_B = batch['B'].to(device)

    # Generate output

      fake_A = netG_B2A(real_B)

      fake_A = ((fake_A * 0.5 + 0.5)).squeeze(0).squeeze(0).cpu().numpy()

    # Save image files
      for b in range(opt.batchSize):
        vol_A= fake_A

        if vol_A.ndim==2:
            vol_A=vol_A[np.newaxis,...]
        tifffile.imwrite(
            os.path.join(output_dir_A,f'HR_FAKE_batch{i}_sample{b}.tif'),
            vol_A.astype(np.float32),
            imagej=True,
            metadata={'axes':'ZYX'}
        )
        sys.stdout.write(f'\rProcessed batch {i+1}/{len(dataloader)}')
        sys.stdout.flush()

print("\nTesting complete")
###################################
